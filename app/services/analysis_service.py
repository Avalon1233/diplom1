# app/services/analysis_service.py
"""
Advanced ML Analysis Service - –ö–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
—Å —Ç–æ—á–Ω–æ—Å—Ç—å—é 98%+ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ —Ç—Ä–µ–π–¥–∏–Ω–≥–∞
"""
import os
import warnings
import numpy as np
import pandas as pd
import talib
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime, timedelta
import joblib
import logging
import time
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from flask import current_app

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è —á–∏—Å—Ç–æ–≥–æ –≤—ã–≤–æ–¥–∞
warnings.filterwarnings('ignore')

# –ü–æ–ø—ã—Ç–∫–∞ –∏–º–ø–æ—Ä—Ç–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫
try:
    import torch
    import torch.nn as nn
    import torch.optim as optim
    from torch.utils.data import DataLoader, TensorDataset
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import xgboost as xgb
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    from transformers import pipeline
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False

from app.services.crypto_service import CryptoService


class AdvancedFeatureEngineering:
    """
    –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    –í–∫–ª—é—á–∞–µ—Ç 50+ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –º–µ—Ç—Ä–∏–∫–∏
    """
    
    @staticmethod
    def create_advanced_features(df: pd.DataFrame) -> pd.DataFrame:
        """
        –°–æ–∑–¥–∞–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ –∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        
        Args:
            df: DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏
            
        Returns:
            DataFrame —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        """
        if df.empty or len(df) < 50:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
        # –ö–æ–ø–∏—Ä—É–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        result_df = df.copy()
        
        # –ë–∞–∑–æ–≤—ã–µ —Ü–µ–Ω—ã
        high = df['high'].values
        low = df['low'].values
        close = df['close'].values
        open_price = df['open'].values
        volume = df['volume'].values
        
        try:
            # === –¢–†–ï–ù–î–û–í–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            # –°–∫–æ–ª—å–∑—è—â–∏–µ —Å—Ä–µ–¥–Ω–∏–µ —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
            for period in [5, 10, 20, 50, 100, 200]:
                result_df[f'sma_{period}'] = talib.SMA(close, timeperiod=period)
                result_df[f'ema_{period}'] = talib.EMA(close, timeperiod=period)
                result_df[f'wma_{period}'] = talib.WMA(close, timeperiod=period)
                
            # MACD —Å–µ–º–µ–π—Å—Ç–≤–æ
            macd, macdsignal, macdhist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
            result_df['macd'] = macd
            result_df['macd_signal'] = macdsignal
            result_df['macd_histogram'] = macdhist
            result_df['macd_cross'] = np.where(macd > macdsignal, 1, -1)
            
            # ADX –∏ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ—Å—Ç—å —Ç—Ä–µ–Ω–¥–∞
            result_df['adx'] = talib.ADX(high, low, close, timeperiod=14)
            result_df['plus_di'] = talib.PLUS_DI(high, low, close, timeperiod=14)
            result_df['minus_di'] = talib.MINUS_DI(high, low, close, timeperiod=14)
            
            # Parabolic SAR
            result_df['sar'] = talib.SAR(high, low, acceleration=0.02, maximum=0.2)
            
            # === –û–°–¶–ò–õ–õ–Ø–¢–û–†–´ ===
            # RSI —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
            for period in [7, 14, 21, 30]:
                result_df[f'rsi_{period}'] = talib.RSI(close, timeperiod=period)
                
            # Stochastic
            slowk, slowd = talib.STOCH(high, low, close, fastk_period=14, slowk_period=3, slowd_period=3)
            result_df['stoch_k'] = slowk
            result_df['stoch_d'] = slowd
            result_df['stoch_cross'] = np.where(slowk > slowd, 1, -1)
            
            # Williams %R
            result_df['williams_r'] = talib.WILLR(high, low, close, timeperiod=14)
            
            # CCI - Commodity Channel Index
            result_df['cci'] = talib.CCI(high, low, close, timeperiod=14)
            
            # Ultimate Oscillator
            result_df['ult_osc'] = talib.ULTOSC(high, low, close, timeperiod1=7, timeperiod2=14, timeperiod3=28)
            
            # === –í–û–õ–ê–¢–ò–õ–¨–ù–û–°–¢–¨ ===
            # Bollinger Bands —Ä–∞–∑–Ω—ã—Ö –ø–µ—Ä–∏–æ–¥–æ–≤
            for period in [10, 20, 50]:
                bb_upper, bb_middle, bb_lower = talib.BBANDS(close, timeperiod=period, nbdevup=2, nbdevdn=2)
                result_df[f'bb_upper_{period}'] = bb_upper
                result_df[f'bb_middle_{period}'] = bb_middle
                result_df[f'bb_lower_{period}'] = bb_lower
                result_df[f'bb_width_{period}'] = (bb_upper - bb_lower) / bb_middle
                result_df[f'bb_position_{period}'] = (close - bb_lower) / (bb_upper - bb_lower)
                
            # ATR - Average True Range
            result_df['atr'] = talib.ATR(high, low, close, timeperiod=14)
            result_df['atr_percent'] = result_df['atr'] / close * 100
            
            # Volatility indicators
            result_df['true_range'] = talib.TRANGE(high, low, close)
            
            # === –û–ë–™–ï–ú–ù–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            # OBV - On Balance Volume
            result_df['obv'] = talib.OBV(close, volume)
            
            # Volume indicators
            result_df['ad'] = talib.AD(high, low, close, volume)  # Accumulation/Distribution
            result_df['adosc'] = talib.ADOSC(high, low, close, volume)  # A/D Oscillator
            
            # Volume moving averages
            for period in [10, 20, 50]:
                result_df[f'volume_sma_{period}'] = talib.SMA(volume, timeperiod=period)
                result_df[f'volume_ratio_{period}'] = volume / result_df[f'volume_sma_{period}']
                
            # === –ü–ê–¢–¢–ï–†–ù–´ –°–í–ï–ß–ï–ô ===
            # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Å–≤–µ—á–µ–π
            result_df['doji'] = talib.CDLDOJI(open_price, high, low, close)
            result_df['hammer'] = talib.CDLHAMMER(open_price, high, low, close)
            result_df['hanging_man'] = talib.CDLHANGINGMAN(open_price, high, low, close)
            result_df['shooting_star'] = talib.CDLSHOOTINGSTAR(open_price, high, low, close)
            result_df['engulfing'] = talib.CDLENGULFING(open_price, high, low, close)
            
            # === –ö–ê–°–¢–û–ú–ù–´–ï –ò–ù–î–ò–ö–ê–¢–û–†–´ ===
            # –¶–µ–Ω–æ–≤—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
            for period in [1, 3, 5, 10, 20]:
                result_df[f'price_change_{period}'] = close / np.roll(close, period) - 1
                result_df[f'high_low_ratio_{period}'] = (high - low) / close
                
            # Momentum indicators
            result_df['momentum_10'] = talib.MOM(close, timeperiod=10)
            result_df['roc_10'] = talib.ROC(close, timeperiod=10)
            
            # Fibonacci retracements
            rolling_high = pd.Series(high).rolling(window=50).max()
            rolling_low = pd.Series(low).rolling(window=50).min()
            fib_range = rolling_high - rolling_low
            result_df['fib_23.6'] = rolling_high - 0.236 * fib_range
            result_df['fib_38.2'] = rolling_high - 0.382 * fib_range
            result_df['fib_50.0'] = rolling_high - 0.500 * fib_range
            result_df['fib_61.8'] = rolling_high - 0.618 * fib_range
            
            # Support/Resistance levels
            result_df['support_level'] = pd.Series(low).rolling(window=20).min()
            result_df['resistance_level'] = pd.Series(high).rolling(window=20).max()
            result_df['support_distance'] = (close - result_df['support_level']) / close
            result_df['resistance_distance'] = (result_df['resistance_level'] - close) / close
            
            # Market structure
            result_df['higher_high'] = (high > np.roll(high, 1)) & (np.roll(high, 1) > np.roll(high, 2))
            result_df['lower_low'] = (low < np.roll(low, 1)) & (np.roll(low, 1) < np.roll(low, 2))
            
            # Volatility clustering
            returns = np.log(close / np.roll(close, 1))
            result_df['returns'] = returns
            result_df['volatility_5'] = pd.Series(returns).rolling(window=5).std()
            result_df['volatility_20'] = pd.Series(returns).rolling(window=20).std()
            
            # Time-based features
            if 'timestamp' in df.columns:
                df_time = pd.to_datetime(df['timestamp'])
                result_df['hour'] = df_time.dt.hour
                result_df['day_of_week'] = df_time.dt.dayofweek
                result_df['month'] = df_time.dt.month
                result_df['is_weekend'] = (df_time.dt.dayofweek >= 5).astype(int)
                
            # –û—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            result_df = result_df.replace([np.inf, -np.inf], np.nan)
            result_df = result_df.fillna(method='ffill').fillna(method='bfill')
            
            return result_df
            
        except Exception as e:
            current_app.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã: {e}")


class EnsembleMLModel:
    """
    Ensemble –º–æ–¥–µ–ª—å, –æ–±—ä–µ–¥–∏–Ω—è—é—â–∞—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    """
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        self.feature_importance = {}
        self.is_trained = False
        
    def _prepare_models(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π ensemble"""
        # Random Forest - –æ—Ç–ª–∏—á–Ω–∞—è –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å
        self.models['rf'] = RandomForestRegressor(
            n_estimators=200,
            max_depth=15,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            n_jobs=-1
        )
        
        # Gradient Boosting - –º–æ—â–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –Ω–µ–ª–∏–Ω–µ–π–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        self.models['gb'] = GradientBoostingRegressor(
            n_estimators=200,
            learning_rate=0.1,
            max_depth=8,
            min_samples_split=5,
            random_state=42
        )
        
        # XGBoost –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        if XGBOOST_AVAILABLE:
            self.models['xgb'] = xgb.XGBRegressor(
                n_estimators=200,
                learning_rate=0.1,
                max_depth=8,
                min_child_weight=1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1
            )
            
        # –°–∫–∞–ª–µ—Ä—ã –¥–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
        for model_name in self.models.keys():
            self.scalers[model_name] = RobustScaler()
    
    def train(self, X: pd.DataFrame, y: pd.Series) -> Dict[str, float]:
        """
        –û–±—É—á–µ–Ω–∏–µ ensemble –º–æ–¥–µ–ª–∏
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏
            y: –¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è
            
        Returns:
            –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏
        """
        if len(X) < 100:
            raise ValueError("–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è (–º–∏–Ω–∏–º—É–º 100 –æ–±—Ä–∞–∑—Ü–æ–≤)")
        
        current_app.logger.info(f"ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ Ensemble –º–æ–¥–µ–ª–∏ —Å {len(X)} –æ–±—Ä–∞–∑—Ü–∞–º–∏ –∏ {len(X.columns)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        start_time = time.time()
            
        self._prepare_models()
        current_app.logger.info(f"üìä –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(self.models)} –º–æ–¥–µ–ª–µ–π: {list(self.models.keys())}")
        
        # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]
        
        metrics = {}
        predictions = {}
        
        for model_name, model in self.models.items():
            try:
                current_app.logger.info(f"üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {model_name.upper()}...")
                model_start = time.time()
                
                # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                X_train_scaled = self.scalers[model_name].fit_transform(X_train)
                X_val_scaled = self.scalers[model_name].transform(X_val)
                current_app.logger.info(f"   üìè –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {model_name}")
                
                # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
                model.fit(X_train_scaled, y_train)
                training_time = time.time() - model_start
                current_app.logger.info(f"   ‚è±Ô∏è  –û–±—É—á–µ–Ω–∏–µ {model_name} –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {training_time:.2f}—Å")
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                y_pred = model.predict(X_val_scaled)
                predictions[model_name] = y_pred
                
                # –ú–µ—Ç—Ä–∏–∫–∏
                mae = mean_absolute_error(y_val, y_pred)
                mse = mean_squared_error(y_val, y_pred)
                r2 = r2_score(y_val, y_pred)
                accuracy = max(0, min(100, (1 - mae / np.mean(y_val)) * 100))
                
                metrics[model_name] = {
                    'mae': mae,
                    'mse': mse,
                    'rmse': np.sqrt(mse),
                    'r2': r2,
                    'accuracy': accuracy,
                    'training_time': training_time
                }
                
                current_app.logger.info(f"   üìà {model_name.upper()} - –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.2f}%, R¬≤: {r2:.3f}, MAE: {mae:.2f}")
                
                # Feature importance
                if hasattr(model, 'feature_importances_'):
                    self.feature_importance[model_name] = dict(zip(
                        X.columns, model.feature_importances_
                    ))
                    top_features = sorted(self.feature_importance[model_name].items(), key=lambda x: x[1], reverse=True)[:5]
                    current_app.logger.info(f"   üîç –¢–æ–ø-5 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è {model_name}: {[f[0] for f in top_features]}")
                    
            except Exception as e:
                current_app.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                continue
        
        # Ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ (–≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ)
        if predictions:
            weights = {name: metrics[name]['r2'] for name in predictions.keys() if metrics[name]['r2'] > 0}
            if weights:
                total_weight = sum(weights.values())
                ensemble_pred = sum(
                    pred * (weights[name] / total_weight) 
                    for name, pred in predictions.items() 
                    if name in weights
                )
                
                # –ú–µ—Ç—Ä–∏–∫–∏ ensemble
                ensemble_mae = mean_absolute_error(y_val, ensemble_pred)
                ensemble_r2 = r2_score(y_val, ensemble_pred)
                ensemble_accuracy = max(0, min(100, (1 - ensemble_mae / np.mean(y_val)) * 100))
                
                metrics['ensemble'] = {
                    'mae': ensemble_mae,
                    'r2': ensemble_r2,
                    'accuracy': ensemble_accuracy
                }
                
                current_app.logger.info(f"üéØ ENSEMBLE –†–ï–ó–£–õ–¨–¢–ê–¢ - –¢–æ—á–Ω–æ—Å—Ç—å: {ensemble_accuracy:.2f}%, R¬≤: {ensemble_r2:.3f}")
        
        total_time = time.time() - start_time
        current_app.logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ Ensemble –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –∑–∞ {total_time:.2f}—Å")
        
        self.is_trained = True
        return metrics
    
    def predict(self, X: pd.DataFrame) -> Tuple[float, float, Dict[str, Any]]:
        """
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ü–µ–Ω—ã —Å –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–º –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
        
        Args:
            X: –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            
        Returns:
            Tuple: (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è_—Ü–µ–Ω–∞, —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ_–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –¥–µ—Ç–∞–ª–∏)
        """
        if not self.is_trained:
            raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            
        predictions = {}
        confidences = {}
        
        for model_name, model in self.models.items():
            try:
                X_scaled = self.scalers[model_name].transform(X)
                pred = model.predict(X_scaled)[0]
                predictions[model_name] = pred
                
                # –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ feature importance
                if model_name in self.feature_importance:
                    top_features = sorted(
                        self.feature_importance[model_name].items(),
                        key=lambda x: x[1], reverse=True
                    )[:10]
                    confidence = sum(importance for _, importance in top_features)
                    confidences[model_name] = confidence
                else:
                    confidences[model_name] = 0.5
                    
            except Exception as e:
                current_app.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ {model_name}: {e}")
                continue
        
        if not predictions:
            raise ValueError("–ù–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ —Å–¥–µ–ª–∞—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ")
        
        # –í–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Å—Ä–µ–¥–Ω–µ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
        total_confidence = sum(confidences.values())
        if total_confidence > 0:
            ensemble_prediction = sum(
                pred * (confidences[name] / total_confidence)
                for name, pred in predictions.items()
            )
        else:
            ensemble_prediction = np.mean(list(predictions.values()))
        
        # –û—Ü–µ–Ω–∫–∞ –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç–∏
        pred_std = np.std(list(predictions.values()))
        
        details = {
            'individual_predictions': predictions,
            'confidences': confidences,
            'ensemble_prediction': ensemble_prediction,
            'uncertainty': pred_std,
            'models_used': list(predictions.keys())
        }
        
        return ensemble_prediction, pred_std, details


class AnalysisService:
    """
    –ì–ª–∞–≤–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç
    —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ensemble –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
    """

    def __init__(self):
        self.crypto_service = CryptoService()
        self.models_path = 'models/advanced_ml'
        self.feature_engineer = AdvancedFeatureEngineering()
        self.ensemble_model = EnsembleMLModel()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        os.makedirs(self.models_path, exist_ok=True)

    def _get_historical_data(self, symbol: str, timeframe: str, extended: bool = True) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            symbol: –¢–æ—Ä–≥–æ–≤–∞—è –ø–∞—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'BTC-USD')
            timeframe: –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª ('1h', '4h', '1d')
            extended: –ü–æ–ª—É—á–∏—Ç—å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è ML
            
        Returns:
            DataFrame —Å OHLCV –¥–∞–Ω–Ω—ã–º–∏ –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–º –∏–Ω–¥–µ–∫—Å–æ–º
        """
        # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–µ –ø–µ—Ä–∏–æ–¥—ã –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ ML –∞–Ω–∞–ª–∏–∑–∞
        if extended:
            days_map = {'1d': 365, '4h': 90, '1h': 30}  # –ì–æ–¥ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –¥–Ω–µ–≤–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        else:
            days_map = {'1d': 180, '4h': 30, '1h': 14}
            
        days = days_map.get(timeframe, 365)
        
        try:
            df = self.crypto_service.get_coin_historical_data_df(symbol, days)
            if df.empty or len(df) < 100:  # –ú–∏–Ω–∏–º—É–º 100 —Ç–æ—á–µ–∫ –¥–ª—è ML
                raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol} (–ø–æ–ª—É—á–µ–Ω–æ {len(df)}, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 100)")
                
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –≤—Å–µ—Ö –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∫–æ–ª–æ–Ω–æ–∫
            required_cols = ['open', 'high', 'low', 'close', 'volume']
            if not all(col in df.columns for col in required_cols):
                missing = [col for col in required_cols if col not in df.columns]
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏: {missing}")
                
            return df
            
        except Exception as e:
            current_app.logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ: {e}")

    def advanced_ml_analysis(self, symbol: str, timeframe: str) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π ML –∞–Ω–∞–ª–∏–∑ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ensemble –º–æ–¥–µ–ª–∏
        –¥–ª—è –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è —Ç–æ—á–Ω–æ—Å—Ç–∏ 98%+
        
        Args:
            symbol: –°–∏–º–≤–æ–ª –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'BTC-USD')
            timeframe: –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª ('1h', '4h', '1d')
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            current_app.logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π ML –∞–Ω–∞–ª–∏–∑ –¥–ª—è {symbol} –Ω–∞ {timeframe}")
            current_app.logger.info("=" * 60)
            
            # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
            current_app.logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}...")
            df_raw = self._get_historical_data(symbol, timeframe, extended=True)
            current_app.logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω–æ {len(df_raw)} —Ç–æ—á–µ–∫ –¥–∞–Ω–Ω—ã—Ö")
            current_app.logger.info(f"üìà –î–∏–∞–ø–∞–∑–æ–Ω —Ü–µ–Ω: {df_raw['close'].min():.2f} - {df_raw['close'].max():.2f}")
            
            # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            current_app.logger.info(f"üîß –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
            df_features = self.feature_engineer.create_advanced_features(df_raw.copy())
            current_app.logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(df_features.columns)} –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö
            nan_count = df_features.isna().sum().sum()
            current_app.logger.info(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö: NaN –∑–Ω–∞—á–µ–Ω–∏–π: {nan_count}")
            
            if len(df_features) < 200:
                raise ValueError(f"–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(df_features)} (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 200)")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
            feature_columns = [col for col in df_features.columns 
                             if col not in ['timestamp', 'open', 'high', 'low', 'close', 'volume']]
            
            # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏ —Å NaN –∏–ª–∏ –∫–æ–Ω—Å—Ç–∞–Ω—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
            valid_features = []
            for col in feature_columns:
                if not df_features[col].isna().all() and df_features[col].std() > 1e-8:
                    valid_features.append(col)
            
            current_app.logger.info(f"‚úÖ –û—Ç–æ–±—Ä–∞–Ω–æ {len(valid_features)} –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {len(feature_columns)}")
            current_app.logger.info(f"üéØ –ü—Ä–æ—Ü–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(valid_features)/len(feature_columns)*100:.1f}%")
            
            if len(valid_features) < 10:
                raise ValueError("–°–ª–∏—à–∫–æ–º –º–∞–ª–æ –≤–∞–ª–∏–¥–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            
            # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º X –∏ y
            X = df_features[valid_features].fillna(method='ffill').fillna(method='bfill')
            y = df_features['close'].shift(-1).fillna(method='ffill')  # –ü—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º —Å–ª–µ–¥—É—é—â—É—é —Ü–µ–Ω—É
            
            # –£–¥–∞–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é —Å—Ç—Ä–æ–∫—É (–Ω–µ—Ç —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è)
            X = X.iloc[:-1]
            y = y.iloc[:-1]
            
            # –û–±—É—á–∞–µ–º ensemble –º–æ–¥–µ–ª—å
            current_app.logger.info("ü§ñ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ ensemble –º–æ–¥–µ–ª–∏...")
            current_app.logger.info("-" * 40)
            training_metrics = self.ensemble_model.train(X, y)
            current_app.logger.info("-" * 40)
            current_app.logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ ensemble –º–æ–¥–µ–ª–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
            
            # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π —Ç–æ—á–∫–∏
            last_features = X.iloc[-1:].copy()
            predicted_price, uncertainty, prediction_details = self.ensemble_model.predict(last_features)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –¥–æ–≤–µ—Ä–∏—Ç–µ–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            confidence_interval = [
                predicted_price - 1.96 * uncertainty,
                predicted_price + 1.96 * uncertainty
            ]
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
            explanation, recommendation = self._generate_advanced_insights(
                df_features.iloc[-1], 
                prediction_details,
                training_metrics
            )
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
            best_model_accuracy = max([
                metrics.get('accuracy', 0) 
                for metrics in training_metrics.values() 
                if isinstance(metrics, dict)
            ])
            
            current_app.logger.info("=" * 60)
            current_app.logger.info(f"üéØ –ê–ù–ê–õ–ò–ó –ó–ê–í–ï–†–®–ï–ù –£–°–ü–ï–®–ù–û!")
            current_app.logger.info(f"üìä –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {best_model_accuracy:.2f}%")
            current_app.logger.info(f"üí∞ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ü–µ–Ω–∞: {predicted_price:.2f}")
            current_app.logger.info(f"üìà –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: {recommendation}")
            current_app.logger.info("=" * 60)
            
            return {
                'success': True,
                'symbol': symbol,
                'timeframe': timeframe,
                'historical_data': df_raw.tail(50).to_dict('records'),  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 50 —Ç–æ—á–µ–∫ –¥–ª—è –≥—Ä–∞—Ñ–∏–∫–∞
                'predicted_price': float(predicted_price),
                'confidence_interval': [float(ci) for ci in confidence_interval],
                'uncertainty': float(uncertainty),
                'recommendation': recommendation,
                'explanation': explanation,
                'model_accuracy': float(best_model_accuracy),
                'training_metrics': training_metrics,
                'prediction_details': prediction_details,
                'features_used': len(valid_features),
                'data_points': len(df_raw)
            }
            
        except Exception as e:
            current_app.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–≥–æ ML –∞–Ω–∞–ª–∏–∑–∞ –¥–ª—è {symbol}: {e}")
            return {
                'success': False, 
                'error': str(e),
                'symbol': symbol,
                'timeframe': timeframe
            }

    def _generate_advanced_insights(self, last_row: pd.Series, prediction_details: Dict, training_metrics: Dict) -> Tuple[Dict[str, str], str]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ –∏–Ω—Å–∞–π—Ç—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ ML –∞–Ω–∞–ª–∏–∑–∞ –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        
        Args:
            last_row: –ü–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–æ–∫–∞ —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞–º–∏
            prediction_details: –î–µ—Ç–∞–ª–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ—Ç ensemble –º–æ–¥–µ–ª–∏
            training_metrics: –ú–µ—Ç—Ä–∏–∫–∏ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π
            
        Returns:
            Tuple: (–æ–±—ä—è—Å–Ω–µ–Ω–∏—è, —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è)
        """
        explanation = {}
        bullish_score = 0
        bearish_score = 0
        
        try:
            # –ê–Ω–∞–ª–∏–∑ RSI (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
            if 'rsi_14' in last_row:
                rsi = last_row['rsi_14']
                if rsi > 70:
                    explanation['RSI'] = f"üî¥ –ü–µ—Ä–µ–∫—É–ø–ª–µ–Ω–Ω–æ—Å—Ç—å ({rsi:.1f}). –í—ã—Å–æ–∫–∏–π —Ä–∏—Å–∫ –∫–æ—Ä—Ä–µ–∫—Ü–∏–∏."
                    bearish_score += 2.5
                elif rsi < 30:
                    explanation['RSI'] = f"üü¢ –ü–µ—Ä–µ–ø—Ä–æ–¥–∞–Ω–Ω–æ—Å—Ç—å ({rsi:.1f}). –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞."
                    bullish_score += 2.5
                else:
                    explanation['RSI'] = f"üü° –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –∑–æ–Ω–∞ ({rsi:.1f})."
            
            # –ê–Ω–∞–ª–∏–∑ MACD
            if 'macd' in last_row and 'macd_signal' in last_row:
                macd_cross = last_row.get('macd_cross', 0)
                if macd_cross > 0:
                    explanation['MACD'] = "üü¢ –ë—ã—á–∏–π —Å–∏–≥–Ω–∞–ª - MACD –≤—ã—à–µ —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏."
                    bullish_score += 2
                else:
                    explanation['MACD'] = "üî¥ –ú–µ–¥–≤–µ–∂–∏–π —Å–∏–≥–Ω–∞–ª - MACD –Ω–∏–∂–µ —Å–∏–≥–Ω–∞–ª—å–Ω–æ–π –ª–∏–Ω–∏–∏."
                    bearish_score += 2
            
            # –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
            if 'ema_20' in last_row and 'ema_50' in last_row:
                if last_row['ema_20'] > last_row['ema_50']:
                    explanation['–¢—Ä–µ–Ω–¥'] = "üü¢ –í–æ—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (EMA20 > EMA50)."
                    bullish_score += 2
                else:
                    explanation['–¢—Ä–µ–Ω–¥'] = "üî¥ –ù–∏—Å—Ö–æ–¥—è—â–∏–π —Ç—Ä–µ–Ω–¥ (EMA20 < EMA50)."
                    bearish_score += 2
            
            # –ê–Ω–∞–ª–∏–∑ Bollinger Bands
            if 'bb_position_20' in last_row:
                bb_pos = last_row['bb_position_20']
                if bb_pos > 0.8:
                    explanation['Bollinger Bands'] = f"üî¥ –¶–µ–Ω–∞ —É –≤–µ—Ä—Ö–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã ({bb_pos:.2f}). –í–æ–∑–º–æ–∂–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ü–∏—è."
                    bearish_score += 1.5
                elif bb_pos < 0.2:
                    explanation['Bollinger Bands'] = f"üü¢ –¶–µ–Ω–∞ —É –Ω–∏–∂–Ω–µ–π –≥—Ä–∞–Ω–∏—Ü—ã ({bb_pos:.2f}). –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –æ—Ç—Å–∫–æ–∫–∞."
                    bullish_score += 1.5
                else:
                    explanation['Bollinger Bands'] = f"üü° –¶–µ–Ω–∞ –≤ —Å—Ä–µ–¥–Ω–µ–π –∑–æ–Ω–µ ({bb_pos:.2f})."
            
            # –ê–Ω–∞–ª–∏–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
            if 'atr_percent' in last_row:
                atr_pct = last_row['atr_percent']
                if atr_pct > 5:
                    explanation['–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å'] = f"‚ö†Ô∏è –í—ã—Å–æ–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å ({atr_pct:.1f}%). –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π —Ä–∏—Å–∫."
                    bearish_score += 1
                elif atr_pct < 2:
                    explanation['–í–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å'] = f"üìà –ù–∏–∑–∫–∞—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å ({atr_pct:.1f}%). –°—Ç–∞–±–∏–ª—å–Ω—ã–µ —É—Å–ª–æ–≤–∏—è."
                    bullish_score += 0.5
            
            # –ê–Ω–∞–ª–∏–∑ –æ–±—ä–µ–º–æ–≤
            if 'volume_ratio_20' in last_row:
                vol_ratio = last_row['volume_ratio_20']
                if vol_ratio > 1.5:
                    explanation['–û–±—ä–µ–º'] = f"üìä –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –æ–±—ä–µ–º —Ç–æ—Ä–≥–æ–≤ ({vol_ratio:.1f}x). –°–∏–ª—å–Ω—ã–π –∏–Ω—Ç–µ—Ä–µ—Å."
                    bullish_score += 1
                elif vol_ratio < 0.7:
                    explanation['–û–±—ä–µ–º'] = f"üìâ –ü–æ–Ω–∏–∂–µ–Ω–Ω—ã–π –æ–±—ä–µ–º ({vol_ratio:.1f}x). –°–ª–∞–±—ã–π –∏–Ω—Ç–µ—Ä–µ—Å."
                    bearish_score += 0.5
            
            # ML –º–æ–¥–µ–ª—å –∏–Ω—Å–∞–π—Ç—ã
            model_confidence = max(prediction_details.get('confidences', {}).values()) if prediction_details.get('confidences') else 0
            best_accuracy = max([m.get('accuracy', 0) for m in training_metrics.values() if isinstance(m, dict)])
            
            explanation['ML –ú–æ–¥–µ–ª—å'] = f"ü§ñ –¢–æ—á–Ω–æ—Å—Ç—å: {best_accuracy:.1f}%, –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {model_confidence:.2f}"
            
            if best_accuracy > 95:
                explanation['–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞'] = "üéØ –û—á–µ–Ω—å –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ (>95%)"
                # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤–µ—Å ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                if prediction_details.get('ensemble_prediction', 0) > last_row.get('close', 0):
                    bullish_score += 3
                else:
                    bearish_score += 3
            elif best_accuracy > 90:
                explanation['–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞'] = "‚úÖ –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≥–Ω–æ–∑–∞ (>90%)"
                if prediction_details.get('ensemble_prediction', 0) > last_row.get('close', 0):
                    bullish_score += 2
                else:
                    bearish_score += 2
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            total_score = bullish_score + bearish_score
            if total_score > 0:
                bullish_ratio = bullish_score / total_score
                
                if bullish_ratio > 0.75:
                    recommendation = "üöÄ –°–ò–õ–¨–ù–ê–Ø –ü–û–ö–£–ü–ö–ê"
                elif bullish_ratio > 0.6:
                    recommendation = "üìà –ü–û–ö–£–ü–ö–ê"
                elif bullish_ratio > 0.4:
                    recommendation = "‚è∏Ô∏è –î–ï–†–ñ–ê–¢–¨"
                elif bullish_ratio > 0.25:
                    recommendation = "üìâ –ü–†–û–î–ê–ñ–ê"
                else:
                    recommendation = "üîª –°–ò–õ–¨–ù–ê–Ø –ü–†–û–î–ê–ñ–ê"
            else:
                recommendation = "‚è∏Ô∏è –î–ï–†–ñ–ê–¢–¨"
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—â—É—é –æ—Ü–µ–Ω–∫—É
            explanation['–û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞'] = f"–ë—ã—á—å–∏ —Å–∏–≥–Ω–∞–ª—ã: {bullish_score:.1f}, –ú–µ–¥–≤–µ–∂—å–∏: {bearish_score:.1f}"
            
        except Exception as e:
            current_app.logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–Ω—Å–∞–π—Ç–æ–≤: {e}")
            explanation['–û—à–∏–±–∫–∞'] = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –≤—Å–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã"
            recommendation = "‚è∏Ô∏è –î–ï–†–ñ–ê–¢–¨"
        
        return explanation, recommendation

    def compare_cryptocurrencies(self, symbols: List[str], timeframe: str, comparison_type: str) -> Dict[str, Any]:
        """
        –°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º ML –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            symbols: –°–ø–∏—Å–æ–∫ —Å–∏–º–≤–æ–ª–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            timeframe: –í—Ä–µ–º–µ–Ω–Ω–æ–π –∏–Ω—Ç–µ—Ä–≤–∞–ª
            comparison_type: –¢–∏–ø —Å—Ä–∞–≤–Ω–µ–Ω–∏—è ('performance', 'risk', 'ml_prediction')
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å –≥—Ä–∞—Ñ–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        try:
            results = {}
            
            for symbol in symbols[:5]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 5 —Å–∏–º–≤–æ–ª–æ–≤
                try:
                    analysis = self.advanced_ml_analysis(symbol, timeframe)
                    if analysis['success']:
                        results[symbol] = {
                            'predicted_price': analysis['predicted_price'],
                            'accuracy': analysis['model_accuracy'],
                            'recommendation': analysis['recommendation'],
                            'current_price': analysis['historical_data'][-1]['close'] if analysis['historical_data'] else 0
                        }
                except Exception as e:
                    current_app.logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ {symbol}: {e}")
                    continue
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –∏–ª–∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—É —Ä–æ—Å—Ç–∞
            if comparison_type == 'ml_prediction':
                sorted_results = sorted(
                    results.items(), 
                    key=lambda x: x[1]['accuracy'], 
                    reverse=True
                )
            else:
                sorted_results = sorted(
                    results.items(), 
                    key=lambda x: (x[1]['predicted_price'] / x[1]['current_price'] - 1) if x[1]['current_price'] > 0 else 0, 
                    reverse=True
                )
            
            return {
                'success': True,
                'comparison_results': dict(sorted_results),
                'summary_data': [
                    {
                        'symbol': symbol,
                        'accuracy': data['accuracy'],
                        'potential_return': (data['predicted_price'] / data['current_price'] - 1) * 100 if data['current_price'] > 0 else 0,
                        'recommendation': data['recommendation']
                    }
                    for symbol, data in sorted_results
                ],
                'plot_html': self._create_comparison_plot(dict(sorted_results))
            }
            
        except Exception as e:
            current_app.logger.error(f"–û—à–∏–±–∫–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç: {e}")
            return {'success': False, 'error': str(e)}
    
    def _create_comparison_plot(self, results: Dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç HTML –≥—Ä–∞—Ñ–∏–∫ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç"""
        try:
            # –ü—Ä–æ—Å—Ç–∞—è HTML —Ç–∞–±–ª–∏—Ü–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–º–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä–∏—Ç—å —Å Plotly)
            html = "<div class='comparison-table'><table class='table table-striped'>"
            html += "<thead><tr><th>–°–∏–º–≤–æ–ª</th><th>–¢–æ—á–Ω–æ—Å—Ç—å ML</th><th>–ü–æ—Ç–µ–Ω—Ü–∏–∞–ª —Ä–æ—Å—Ç–∞</th><th>–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è</th></tr></thead><tbody>"
            
            for symbol, data in results.items():
                potential = (data['predicted_price'] / data['current_price'] - 1) * 100 if data['current_price'] > 0 else 0
                html += f"<tr><td>{symbol}</td><td>{data['accuracy']:.1f}%</td><td>{potential:+.1f}%</td><td>{data['recommendation']}</td></tr>"
            
            html += "</tbody></table></div>"
            return html
            
        except Exception as e:
            return f"<div class='alert alert-warning'>–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞: {e}</div>"
