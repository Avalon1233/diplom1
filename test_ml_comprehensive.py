#!/usr/bin/env python3
"""
–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ML-–º–æ–¥–µ–ª–∏ —Å –±—ç–∫—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ –∞–Ω–∞–ª–∏–∑–æ–º —Ç–æ—á–Ω–æ—Å—Ç–∏
"""
import sys
import os
import json
from datetime import datetime

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –ø—Ä–æ–µ–∫—Ç—É
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app import create_app
from app.services.backtesting_service import run_comprehensive_model_evaluation, BacktestingService


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    print("–ó–∞–ø—É—Å–∫ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è ML-–º–æ–¥–µ–ª–∏")
    print("=" * 60)
    
    # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    app = create_app()
    
    with app.app_context():
        try:
            # –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã
            test_configs = [
                {'symbol': 'BTC-USD', 'timeframe': '1d'},
                {'symbol': 'ETH-USD', 'timeframe': '1d'},
                {'symbol': 'BTC-USD', 'timeframe': '1w'},
            ]
            
            all_results = {}
            
            for config in test_configs:
                symbol = config['symbol']
                timeframe = config['timeframe']
                
                print(f"\nüìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ {symbol} ({timeframe})")
                print("-" * 40)
                
                try:
                    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ–ª–Ω—É—é –æ—Ü–µ–Ω–∫—É –º–æ–¥–µ–ª–∏
                    results = run_comprehensive_model_evaluation(symbol, timeframe)
                    all_results[f"{symbol}_{timeframe}"] = results
                    
                    # –í—ã–≤–æ–¥–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
                    if 'backtest' in results and 'performance_metrics' in results['backtest']:
                        metrics = results['backtest']['performance_metrics']
                        print(f"‚úÖ –¢–æ—á–Ω–æ—Å—Ç—å: {metrics.get('accuracy', 0):.2f}%")
                        print(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {metrics.get('direction_accuracy', 0):.2f}%")
                        print(f"üìä R¬≤ Score: {metrics.get('r2_score', 0):.3f}")
                        print(f"üí∞ Sharpe Ratio: {metrics.get('sharpe_ratio', 0):.3f}")
                        print(f"üìâ –ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞: {metrics.get('max_drawdown', 0):.2f}%")
                    
                    if 'cross_validation' in results:
                        cv_metrics = results['cross_validation']
                        print(f"üîÑ CV MAPE: {cv_metrics.get('mean_mape', 0):.2f}% ¬± {cv_metrics.get('std_mape', 0):.2f}%")
                    
                    # –í—ã–≤–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
                    if 'overall_recommendations' in results:
                        print("\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
                        for rec in results['overall_recommendations']:
                            print(f"   {rec}")
                    
                except Exception as e:
                    print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ {symbol} ({timeframe}): {e}")
                    all_results[f"{symbol}_{timeframe}"] = {'error': str(e)}
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            results_file = f"ml_comprehensive_test_results_{timestamp}.json"
            
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
            
            print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_file}")
            
            # –°–æ–∑–¥–∞–µ–º —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç
            create_summary_report(all_results, timestamp)
            
        except Exception as e:
            print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
            return 1
    
    print("\n‚úÖ –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
    return 0


def create_summary_report(results: dict, timestamp: str):
    """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è"""
    report_file = f"ml_test_summary_{timestamp}.md"
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("# üìä –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç –ø–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—é ML-–º–æ–¥–µ–ª–∏\n\n")
        f.write(f"**–î–∞—Ç–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_tests = len(results)
        successful_tests = sum(1 for r in results.values() if 'error' not in r)
        
        f.write(f"**–û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:**\n")
        f.write(f"- –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {total_tests}\n")
        f.write(f"- –£—Å–ø–µ—à–Ω—ã—Ö: {successful_tests}\n")
        f.write(f"- –ù–µ—É–¥–∞—á–Ω—ã—Ö: {total_tests - successful_tests}\n\n")
        
        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        f.write("## üìà –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n")
        
        for test_name, result in results.items():
            f.write(f"### {test_name}\n\n")
            
            if 'error' in result:
                f.write(f"‚ùå **–û—à–∏–±–∫–∞:** {result['error']}\n\n")
                continue
            
            # –ë—ç–∫—Ç–µ—Å—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'backtest' in result and 'performance_metrics' in result['backtest']:
                metrics = result['backtest']['performance_metrics']
                f.write("**–ë—ç–∫—Ç–µ—Å—Ç –º–µ—Ç—Ä–∏–∫–∏:**\n")
                f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å: {metrics.get('accuracy', 0):.2f}%\n")
                f.write(f"- –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {metrics.get('direction_accuracy', 0):.2f}%\n")
                f.write(f"- R¬≤ Score: {metrics.get('r2_score', 0):.3f}\n")
                f.write(f"- MAE: {metrics.get('mae', 0):.2f}\n")
                f.write(f"- MAPE: {metrics.get('mape', 0):.2f}%\n")
                f.write(f"- Sharpe Ratio: {metrics.get('sharpe_ratio', 0):.3f}\n")
                f.write(f"- –ú–∞–∫—Å. –ø—Ä–æ—Å–∞–¥–∫–∞: {metrics.get('max_drawdown', 0):.2f}%\n\n")
            
            # Cross-validation —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            if 'cross_validation' in result:
                cv = result['cross_validation']
                f.write("**Cross-Validation –º–µ—Ç—Ä–∏–∫–∏:**\n")
                f.write(f"- –°—Ä–µ–¥–Ω—è—è MAPE: {cv.get('mean_mape', 0):.2f}% ¬± {cv.get('std_mape', 0):.2f}%\n")
                f.write(f"- –°—Ä–µ–¥–Ω–∏–π R¬≤: {cv.get('mean_r2', 0):.3f} ¬± {cv.get('std_r2', 0):.3f}\n")
                f.write(f"- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–æ–ª–¥–æ–≤: {cv.get('cv_folds', 0)}\n\n")
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
            if 'overall_recommendations' in result:
                f.write("**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**\n")
                for rec in result['overall_recommendations']:
                    f.write(f"- {rec}\n")
                f.write("\n")
        
        # –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã
        f.write("## üéØ –û–±—â–∏–µ –≤—ã–≤–æ–¥—ã\n\n")
        
        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        accuracies = []
        direction_accuracies = []
        r2_scores = []
        
        for result in results.values():
            if 'error' not in result and 'backtest' in result:
                metrics = result['backtest'].get('performance_metrics', {})
                if metrics.get('accuracy'):
                    accuracies.append(metrics['accuracy'])
                if metrics.get('direction_accuracy'):
                    direction_accuracies.append(metrics['direction_accuracy'])
                if metrics.get('r2_score'):
                    r2_scores.append(metrics['r2_score'])
        
        if accuracies:
            avg_accuracy = sum(accuracies) / len(accuracies)
            f.write(f"- **–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å:** {avg_accuracy:.2f}%\n")
            
            if avg_accuracy >= 85:
                f.write("- ‚úÖ **–û—Ü–µ–Ω–∫–∞:** –û–¢–õ–ò–ß–ù–ê–Ø –º–æ–¥–µ–ª—å, –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É\n")
            elif avg_accuracy >= 75:
                f.write("- ‚ö†Ô∏è **–û—Ü–µ–Ω–∫–∞:** –•–û–†–û–®–ê–Ø –º–æ–¥–µ–ª—å, —Ç—Ä–µ–±—É–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞\n")
            else:
                f.write("- ‚ùå **–û—Ü–µ–Ω–∫–∞:** –ú–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö —É–ª—É—á—à–µ–Ω–∏–π\n")
        
        if direction_accuracies:
            avg_direction = sum(direction_accuracies) / len(direction_accuracies)
            f.write(f"- **–°—Ä–µ–¥–Ω—è—è —Ç–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è:** {avg_direction:.2f}%\n")
        
        if r2_scores:
            avg_r2 = sum(r2_scores) / len(r2_scores)
            f.write(f"- **–°—Ä–µ–¥–Ω–∏–π R¬≤ Score:** {avg_r2:.3f}\n")
    
    print(f"üìÑ –°–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}")


def run_quick_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–¥–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    print("–ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ –º–æ–¥–µ–ª–∏")
    
    app = create_app()
    with app.app_context():
        backtesting_service = BacktestingService()
        
        try:
            # –ë—ã—Å—Ç—Ä—ã–π –±—ç–∫—Ç–µ—Å—Ç –Ω–∞ 10 –ø–µ—Ä–∏–æ–¥–∞—Ö
            results = backtesting_service.comprehensive_backtest(
                symbol='BTC-USD',
                timeframe='1d',
                test_periods=10,
                retrain_frequency=5
            )
            
            metrics = results['performance_metrics']
            print(f"‚úÖ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∑–∞–≤–µ—Ä—à–µ–Ω:")
            print(f"   –¢–æ—á–Ω–æ—Å—Ç—å: {metrics.get('accuracy', 0):.2f}%")
            print(f"   –¢–æ—á–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è: {metrics.get('direction_accuracy', 0):.2f}%")
            print(f"   R¬≤ Score: {metrics.get('r2_score', 0):.3f}")
            
            return results
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞: {e}")
            return None


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description='–ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ ML-–º–æ–¥–µ–ª–∏')
    parser.add_argument('--quick', action='store_true', help='–ó–∞–ø—É—Å—Ç–∏—Ç—å –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç')
    
    args = parser.parse_args()
    
    if args.quick:
        run_quick_test()
    else:
        exit_code = main()
        sys.exit(exit_code)
